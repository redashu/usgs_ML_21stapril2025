{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a953871-016f-42fb-9997-63d6548ef761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5732d0-91e8-4746-bcb4-d5e6e6570dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset of NLTK \n",
    "#nltk.download('all')\n",
    "# Corpora --punkt,stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23514a3b-edf0-4932-a2a0-5368589704cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating random data\n",
    "my_data = \"Learning NLP is fun! but doing it practically is really awesome.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477d7d48-afd8-430e-9a98-92e852c2eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word tokens:  ['Learning', 'NLP', 'is', 'fun', '!', 'but', 'doing', 'it', 'practically', 'is', 'really', 'awesome', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK is doing tokenization\n",
    "words = nltk.word_tokenize(my_data)\n",
    "print(\"word tokens: \",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f331a06-1281-4757-a44b-62d01cbc6c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Learning NLP is fun!', 'but doing it practically is really awesome.']\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization \n",
    "sent1 = nltk.sent_tokenize(my_data)\n",
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f68de48-6731-4e42-abee-6a513ab8ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting stopwords in supported language \n",
    "from nltk.corpus import stopwords\n",
    "# you can download only stopwords\n",
    "#nltk.download('stopwords')\n",
    "all_lang = stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806c0757-5749-4c70-be7e-a249c36a23b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> albanian\n",
      "--> arabic\n",
      "--> azerbaijani\n",
      "--> basque\n",
      "--> belarusian\n",
      "--> bengali\n",
      "--> catalan\n",
      "--> chinese\n",
      "--> danish\n",
      "--> dutch\n",
      "--> english\n",
      "--> finnish\n",
      "--> french\n",
      "--> german\n",
      "--> greek\n",
      "--> hebrew\n",
      "--> hinglish\n",
      "--> hungarian\n",
      "--> indonesian\n",
      "--> italian\n",
      "--> kazakh\n",
      "--> nepali\n",
      "--> norwegian\n",
      "--> portuguese\n",
      "--> romanian\n",
      "--> russian\n",
      "--> slovene\n",
      "--> spanish\n",
      "--> swedish\n",
      "--> tajik\n",
      "--> tamil\n",
      "--> turkish\n"
     ]
    }
   ],
   "source": [
    "for lang in all_lang:\n",
    "    print(f\"--> {lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47a96a9-94dc-4298-a94a-f5b5cbab55c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "# listing stopwords in particular language\n",
    "eng_stopwords = stopwords.words('english')\n",
    "print(eng_stopwords)\n",
    "print(len(eng_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8717aea0-04fe-4670-bd31-a514d6179538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', ':', '``', 'The', 'Whispering', 'Classroom', \"''\", 'In', '2025', ',', 'classrooms', 'were', 'no', 'longer', 'silent', '.', 'Not', 'because', 'of', 'chatter—but', 'because', 'of', 'AI', '.', 'Ms.', 'Kapoor', ',', 'a', 'high', 'school', 'teacher', 'in', 'Jaipur', ',', 'had', 'recently', 'integrated', '“', 'EVA', ',', '”', 'an', 'AI-powered', 'assistant', ',', 'into', 'her', 'classroom', '.', 'EVA', 'whispered', 'personalized', 'tips', 'into', 'students', '’', 'earbuds—reminding', 'Aarav', 'about', 'formulas', ',', 'helping', 'Sana', 'organize', 'her', 'essay', ',', 'and', 'encouraging', 'Mehul', 'to', 'try', 'again', 'after', 'a', 'wrong', 'answer', '.', 'At', 'first', ',', 'students', 'were', 'skeptical', '.', 'But', 'soon', ',', 'they', 'found', 'themselves', 'learning', 'faster', ',', 'asking', 'deeper', 'questions', ',', 'and', 'even', 'staying', 'after', 'school—voluntarily', '.', 'EVA', 'adjusted', 'to', 'each', 'student', '’', 's', 'pace', ',', 'interest', ',', 'and', 'mood', '.', 'Ms.', 'Kapoor', 'was', 'finally', 'free', 'from', 'endless', 'grading', 'and', 'could', 'focus', 'on', 'mentoring', 'and', 'guiding', ',', 'not', 'just', 'teaching', '.', 'One', 'day', ',', 'the', 'internet', 'went', 'down', '.', 'EVA', 'fell', 'silent', '.', 'The', 'students', 'froze', ',', 'expecting', 'chaos', '.', 'But', 'surprisingly', ',', 'they', 'began', 'helping', 'each', 'other', ',', 'recalling', 'tips', ',', 'and', 'using', 'old-school', 'methods', '.', 'It', 'turned', 'out', 'that', 'while', 'EVA', 'had', 'whispered', ',', 'it', 'had', 'also', 'empowered', '.', 'The', 'classroom', 'wasn', '’', 't', 'just', 'smart—it', 'was', 'alive', '.', 'When', 'the', 'connection', 'returned', ',', 'EVA', 'chimed', 'back', 'in', ':', '“', 'Well', 'done.', '”', 'AI', 'didn', '’', 't', 'replace', 'teaching—it', 'amplified', 'it']\n",
      "220\n"
     ]
    }
   ],
   "source": [
    "# data to remove stopwords\n",
    "data1 = \"\"\"\n",
    "Title: \"The Whispering Classroom\"\n",
    "In 2025, classrooms were no longer silent. Not because of chatter—but because of AI. Ms. Kapoor, a high school teacher in Jaipur, had recently integrated “EVA,” an AI-powered assistant, into her classroom. EVA whispered personalized tips into students’ earbuds—reminding Aarav about formulas, helping Sana organize her essay, and encouraging Mehul to try again after a wrong answer.\n",
    "At first, students were skeptical. But soon, they found themselves learning faster, asking deeper questions, and even staying after school—voluntarily. EVA adjusted to each student’s pace, interest, and mood. Ms. Kapoor was finally free from endless grading and could focus on mentoring and guiding, not just teaching.\n",
    "One day, the internet went down. EVA fell silent.\n",
    "The students froze, expecting chaos. But surprisingly, they began helping each other, recalling tips, and using old-school methods. It turned out that while EVA had whispered, it had also empowered. The classroom wasn’t just smart—it was alive.\n",
    "When the connection returned, EVA chimed back in: “Well done.”\n",
    "AI didn’t replace teaching—it amplified it\n",
    "\"\"\"\n",
    "# word tokenization \n",
    "data1_words = nltk.word_tokenize(data1)\n",
    "print(data1_words)\n",
    "print(len(data1_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c54305-92f8-4896-bbb4-4f53539b9c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Title', ':', '``', 'Whispering', 'Classroom', \"''\", '2025', ',', 'classrooms', 'longer', 'silent', '.', 'chatter—but', 'AI', '.', 'Ms.', 'Kapoor', ',', 'high', 'school', 'teacher', 'Jaipur', ',', 'recently', 'integrated', '“', 'EVA', ',', '”', 'AI-powered', 'assistant', ',', 'classroom', '.', 'EVA', 'whispered', 'personalized', 'tips', 'students', '’', 'earbuds—reminding', 'Aarav', 'formulas', ',', 'helping', 'Sana', 'organize', 'essay', ',', 'encouraging', 'Mehul', 'try', 'wrong', 'answer', '.', 'first', ',', 'students', 'skeptical', '.', 'soon', ',', 'found', 'learning', 'faster', ',', 'asking', 'deeper', 'questions', ',', 'even', 'staying', 'school—voluntarily', '.', 'EVA', 'adjusted', 'student', '’', 'pace', ',', 'interest', ',', 'mood', '.', 'Ms.', 'Kapoor', 'finally', 'free', 'endless', 'grading', 'could', 'focus', 'mentoring', 'guiding', ',', 'teaching', '.', 'One', 'day', ',', 'internet', 'went', '.', 'EVA', 'fell', 'silent', '.', 'students', 'froze', ',', 'expecting', 'chaos', '.', 'surprisingly', ',', 'began', 'helping', ',', 'recalling', 'tips', ',', 'using', 'old-school', 'methods', '.', 'turned', 'EVA', 'whispered', ',', 'also', 'empowered', '.', 'classroom', '’', 'smart—it', 'alive', '.', 'connection', 'returned', ',', 'EVA', 'chimed', 'back', ':', '“', 'Well', 'done.', '”', 'AI', '’', 'replace', 'teaching—it', 'amplified']\n"
     ]
    }
   ],
   "source": [
    "# convert data1_words into small cases \n",
    "final_data = []\n",
    "for data in data1_words:\n",
    "    if data.lower() not in eng_stopwords:\n",
    "        final_data.append(data)\n",
    "# data without stopwords\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ebc75ea-8ed0-44bb-aefb-ecfca14f7959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "print(len(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc03d23d-b6d7-456e-bf67-e843f19961ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: textblob\n",
      "Version: 0.19.0\n",
      "Summary: Simple, Pythonic text processing. Sentiment analysis, part-of-speech tagging, noun phrase parsing, and more.\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Steven Loria <sloria1@gmail.com>\n",
      "License: \n",
      "Location: /home/learntechbyme/usgs/lib/python3.12/site-packages\n",
      "Requires: nltk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# Implementing textblob for NLP \n",
    "!pip3 show textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5285a3ce-0322-423a-95d6-e1387ae6b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "my_data1 = \"Learning NLP is fun! but doing it practically is really awesome.\"\n",
    "#  creating blob \n",
    "blob = TextBlob(my_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bded3cc9-625e-4be9-9998-7b6cb767e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"Learning NLP is fun!\"), Sentence(\"but doing it practically is really awesome.\")]\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenize\n",
    "print(blob.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c794a6-ced7-44c7-89ad-fd2aa6cdd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Learning', 'NLP', 'is', 'fun', 'but', 'doing', 'it', 'practically', 'is', 'really', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "# word tokenize \n",
    "print(blob.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d24bbf7-cfa4-438a-ab21-108618724e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment polarity :  0.6875\n"
     ]
    }
   ],
   "source": [
    "# POlarity of blob\n",
    "print(\"sentiment polarity : \",blob.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51478c8-e751-44dd-b161-d80722a01aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
